[
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ouwen Jia",
    "section": "",
    "text": "Hi this is Owen, welcome to my website."
  },
  {
    "objectID": "blog/project1/index.html",
    "href": "blog/project1/index.html",
    "title": "This is Project 1",
    "section": "",
    "text": "I cleaned some data\n\n\n\nI analyzed the data\n#| message: false\nlibrary(tidyverse) mtcars |&gt; ggplot(aes(x = wt, y = mpg)) + geom_point()"
  },
  {
    "objectID": "blog/project1/index.html#section-1-data",
    "href": "blog/project1/index.html#section-1-data",
    "title": "This is Project 1",
    "section": "",
    "text": "I cleaned some data"
  },
  {
    "objectID": "blog/project1/index.html#section-2-analysis",
    "href": "blog/project1/index.html#section-2-analysis",
    "title": "This is Project 1",
    "section": "",
    "text": "I analyzed the data\n#| message: false\nlibrary(tidyverse) mtcars |&gt; ggplot(aes(x = wt, y = mpg)) + geom_point()"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "Matching Donations and Charitable Giving: A Replication Study\n\n\n\n\nOuwen Jia\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOuwen Jia\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoisson Regression Examples\n\n\n\n\nOuwen Jia\nMay 6, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/project2/index.html",
    "href": "blog/project2/index.html",
    "title": "Ouwen Jia",
    "section": "",
    "text": "Hi this is Owen, welcome to my website."
  },
  {
    "objectID": "blog/project1/project1_index.html",
    "href": "blog/project1/project1_index.html",
    "title": "This is Project 1",
    "section": "",
    "text": "I cleaned some data\n\n\n\nI analyzed the data\n#| message: false\nlibrary(tidyverse) mtcars |&gt; ggplot(aes(x = wt, y = mpg)) + geom_point()"
  },
  {
    "objectID": "blog/project1/project1_index.html#section-1-data",
    "href": "blog/project1/project1_index.html#section-1-data",
    "title": "This is Project 1",
    "section": "",
    "text": "I cleaned some data"
  },
  {
    "objectID": "blog/project1/project1_index.html#section-2-analysis",
    "href": "blog/project1/project1_index.html#section-2-analysis",
    "title": "This is Project 1",
    "section": "",
    "text": "I analyzed the data\n#| message: false\nlibrary(tidyverse) mtcars |&gt; ggplot(aes(x = wt, y = mpg)) + geom_point()"
  },
  {
    "objectID": "blog/project2/project2_index.html",
    "href": "blog/project2/project2_index.html",
    "title": "Ouwen Jia",
    "section": "",
    "text": "Hi this is Owen, welcome to my website."
  },
  {
    "objectID": "blog/project3/hw2_questions.html",
    "href": "blog/project3/hw2_questions.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\n\n\nggplot(data, aes(x = patents, fill = iscustomer)) +\n  geom_histogram(position = \"identity\", alpha = 0.5, bins = 30) +\n  labs(\n    title = \"Number of Patents by Customer Status\",\n    x = \"Patents (Last 5 Years)\",\n    fill = \"Customer Status\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\ndata %&gt;%\n  group_by(iscustomer) %&gt;%\n  summarise(\n    count = n(),\n    mean_patents = mean(patents),\n    sd_patents = sd(patents)\n  )\n\n# A tibble: 2 × 4\n  iscustomer   count mean_patents sd_patents\n  &lt;fct&gt;        &lt;int&gt;        &lt;dbl&gt;      &lt;dbl&gt;\n1 Non-Customer  1019         3.47       2.23\n2 Customer       481         4.13       2.55\n\n\nWe observe that Blueprinty customers, on average, have more patents over the past five years. However, this comparison does not yet account for potential confounding variables.\n\n\n\n\nggplot(data, aes(x = region, fill = iscustomer)) +\n  geom_bar(position = \"fill\") +\n  labs(\n    title = \"Regional Distribution by Customer Status\",\n    x = \"Region\",\n    y = \"Proportion of Firms\",\n    fill = \"Customer Status\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThere are noticeable regional differences in customer adoption. Some regions appear to have a higher share of Blueprinty customers.\n\n\n\n\nggplot(data, aes(x = age, fill = iscustomer)) +\n  geom_histogram(position = \"identity\", alpha = 0.5, bins = 30) +\n  labs(\n    title = \"Firm Age Distribution by Customer Status\",\n    x = \"Age (Years Since Incorporation)\",\n    fill = \"Customer Status\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\ndata %&gt;%\n  group_by(iscustomer) %&gt;%\n  summarise(\n    mean_age = mean(age),\n    sd_age = sd(age)\n  )\n\n# A tibble: 2 × 3\n  iscustomer   mean_age sd_age\n  &lt;fct&gt;           &lt;dbl&gt;  &lt;dbl&gt;\n1 Non-Customer     26.1   6.95\n2 Customer         26.9   7.81\n\n\nOn average, customers are older firms. Age may therefore be a confounding factor when evaluating patent success.\n\n\n\nWhile customers have more patents on average, they also differ in age and region. These structural differences suggest we should adjust for confounding variables in any attempt to infer a causal impact of Blueprinty’s software.\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\nThe probability mass function for a Poisson distribution is:\n\\(f(Y | \\lambda) = \\frac{e^{-\\lambda} \\lambda^Y}{Y!}\\)\nWe treat the observed number of patents as realizations from this distribution.\n\n\n\n# Log-likelihood function for Poisson model\npoisson_loglikelihood &lt;- function(lambda, Y) {\n  if (lambda &lt;= 0) return(-Inf)  # Poisson lambda must be positive\n  sum(dpois(Y, lambda, log = TRUE))\n}\n\n\n\n\nWe use the observed number of patents as input to our log-likelihood function.\n\nY_obs &lt;- data$patents\nlambda_vals &lt;- seq(0.1, 10, by = 0.1)\nloglik_vals &lt;- sapply(lambda_vals, function(l) poisson_loglikelihood(l, Y_obs))\n\nplot(lambda_vals, loglik_vals, type = \"l\", lwd = 2,\n     main = \"Log-Likelihood of Poisson Model\",\n     xlab = expression(lambda), ylab = \"Log-Likelihood\")\n\n\n\n\n\n\n\n\n\n\n\nWe now use optim() to find the value of lambda that maximizes the log-likelihood.\n\nmle_result &lt;- optim(par = 1, fn = function(l) -poisson_loglikelihood(l, Y_obs),\n                    method = \"Brent\", lower = 0.01, upper = 20)\n\nlambda_mle &lt;- mle_result$par\nlambda_mle\n\n[1] 3.684667\n\n\nThe MLE for \\(\\lambda\\) is the sample mean of \\(Y\\), which is consistent with theory: for Poisson-distributed data, \\(\\hat{\\lambda}_{MLE} = \\bar{Y}\\).\n\nmean(Y_obs)\n\n[1] 3.684667\n\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\n\n\npoisson_regression_loglik &lt;- function(beta, Y, X) {\n  lambda &lt;- exp(X %*% beta)\n  sum(dpois(Y, lambda, log = TRUE))\n}\n\n\n\n\n\n# Age and age squared\ndata &lt;- data %&gt;%\n  mutate(age_sq = age^2)\n\n# One-hot encode region (drop 1 category)\nregion_dummies &lt;- model.matrix(~ region, data = data)[, -1]\n\n# Final covariate matrix: intercept, age, age_sq, region dummies, customer\nX &lt;- cbind(\n  intercept = 1,\n  age = data$age,\n  age_sq = data$age_sq,\n  region_dummies,\n  iscustomer = as.numeric(data$iscustomer == \"Customer\")\n)\n\nY &lt;- data$patents\n\n\n\n\n\nloglik_wrapper &lt;- function(beta) -poisson_regression_loglik(beta, Y, X)\n\n# Initial guess\nbeta_init &lt;- rep(0, ncol(X))\n\n# Optimize\nopt_result &lt;- optim(par = beta_init, fn = loglik_wrapper, hessian = TRUE, method = \"BFGS\")\n\n# Coefficients\nbeta_hat &lt;- opt_result$par\n\n# Standard errors from Hessian\nhess_inv &lt;- solve(opt_result$hessian)\nse_hat &lt;- sqrt(diag(hess_inv))\n\n# Summary table\ncoef_table &lt;- data.frame(\n  Term = colnames(X),\n  Estimate = beta_hat,\n  StdError = se_hat\n)\n\ncoef_table\n\n             Term     Estimate     StdError\n1       intercept -0.125735914 0.1122180345\n2             age  0.115793715 0.0063574229\n3          age_sq -0.002228748 0.0000771291\n4 regionNortheast -0.024556782 0.0433762879\n5 regionNorthwest -0.034827790 0.0529311002\n6     regionSouth -0.005441860 0.0524007440\n7 regionSouthwest -0.037784109 0.0471722463\n8      iscustomer  0.060665584 0.0320588299\n\n\n\n\n\n\nglm_model &lt;- glm(patents ~ age + I(age^2) + region + iscustomer,\n                 family = poisson(link = \"log\"),\n                 data = data)\n\nsummary(glm_model)\n\n\nCall:\nglm(formula = patents ~ age + I(age^2) + region + iscustomer, \n    family = poisson(link = \"log\"), data = data)\n\nCoefficients:\n                    Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)        -0.508920   0.183179  -2.778  0.00546 ** \nage                 0.148619   0.013869  10.716  &lt; 2e-16 ***\nI(age^2)           -0.002971   0.000258 -11.513  &lt; 2e-16 ***\nregionNortheast     0.029170   0.043625   0.669  0.50372    \nregionNorthwest    -0.017574   0.053781  -0.327  0.74383    \nregionSouth         0.056561   0.052662   1.074  0.28281    \nregionSouthwest     0.050576   0.047198   1.072  0.28391    \niscustomerCustomer  0.207591   0.030895   6.719 1.83e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 2362.5  on 1499  degrees of freedom\nResidual deviance: 2143.3  on 1492  degrees of freedom\nAIC: 6532.1\n\nNumber of Fisher Scoring iterations: 5\n\n\n\n\n\nThis Poisson regression estimates the expected number of patents awarded to firms as a function of age, age squared, region, and Blueprinty software usage. Key insights include:\n\nage: The coefficient is positive and highly significant. This suggests that older firms tend to have more patents, all else equal. Specifically, a one-year increase in firm age is associated with an expected increase in patents by a factor of exp(0.1486) ≈ 1.160 (or about a 16% increase).\nI(age²): The negative and significant coefficient on age squared indicates a concave (inverted U-shaped) relationship. This means that the rate of increase in patents slows down for very old firms.\nregion: None of the regional dummy variables (Northeast, Northwest, South, Southwest) are statistically significant. This implies that — after controlling for age and Blueprinty usage — there are no strong regional differences in patent counts.\niscustomerCustomer: The coefficient is positive and highly significant (p &lt; 0.001). Using Blueprinty’s software is associated with an increase in the expected number of patents. The estimated coefficient 0.208 corresponds to a 23.1% increase in expected patent count (exp(0.208) ≈ 1.231).\n\n\n\n\n\n# Create X_0 and X_1 matrices\nX_0 &lt;- X\nX_0[, \"iscustomer\"] &lt;- 0\n\nX_1 &lt;- X\nX_1[, \"iscustomer\"] &lt;- 1\n\n# Predicted lambda for each case\nlambda_0 &lt;- exp(X_0 %*% beta_hat)\nlambda_1 &lt;- exp(X_1 %*% beta_hat)\n\n# Predicted difference\ndiff &lt;- lambda_1 - lambda_0\nmean(diff)\n\n[1] 0.2178843\n\n\nThis gives the average expected increase in the number of patents due to using Blueprinty’s software, across all firms in the dataset."
  },
  {
    "objectID": "blog/project3/hw2_questions.html#blueprinty-case-study",
    "href": "blog/project3/hw2_questions.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\n\n\nggplot(data, aes(x = patents, fill = iscustomer)) +\n  geom_histogram(position = \"identity\", alpha = 0.5, bins = 30) +\n  labs(\n    title = \"Number of Patents by Customer Status\",\n    x = \"Patents (Last 5 Years)\",\n    fill = \"Customer Status\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\ndata %&gt;%\n  group_by(iscustomer) %&gt;%\n  summarise(\n    count = n(),\n    mean_patents = mean(patents),\n    sd_patents = sd(patents)\n  )\n\n# A tibble: 2 × 4\n  iscustomer   count mean_patents sd_patents\n  &lt;fct&gt;        &lt;int&gt;        &lt;dbl&gt;      &lt;dbl&gt;\n1 Non-Customer  1019         3.47       2.23\n2 Customer       481         4.13       2.55\n\n\nWe observe that Blueprinty customers, on average, have more patents over the past five years. However, this comparison does not yet account for potential confounding variables.\n\n\n\n\nggplot(data, aes(x = region, fill = iscustomer)) +\n  geom_bar(position = \"fill\") +\n  labs(\n    title = \"Regional Distribution by Customer Status\",\n    x = \"Region\",\n    y = \"Proportion of Firms\",\n    fill = \"Customer Status\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThere are noticeable regional differences in customer adoption. Some regions appear to have a higher share of Blueprinty customers.\n\n\n\n\nggplot(data, aes(x = age, fill = iscustomer)) +\n  geom_histogram(position = \"identity\", alpha = 0.5, bins = 30) +\n  labs(\n    title = \"Firm Age Distribution by Customer Status\",\n    x = \"Age (Years Since Incorporation)\",\n    fill = \"Customer Status\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\ndata %&gt;%\n  group_by(iscustomer) %&gt;%\n  summarise(\n    mean_age = mean(age),\n    sd_age = sd(age)\n  )\n\n# A tibble: 2 × 3\n  iscustomer   mean_age sd_age\n  &lt;fct&gt;           &lt;dbl&gt;  &lt;dbl&gt;\n1 Non-Customer     26.1   6.95\n2 Customer         26.9   7.81\n\n\nOn average, customers are older firms. Age may therefore be a confounding factor when evaluating patent success.\n\n\n\nWhile customers have more patents on average, they also differ in age and region. These structural differences suggest we should adjust for confounding variables in any attempt to infer a causal impact of Blueprinty’s software.\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\nThe probability mass function for a Poisson distribution is:\n\\(f(Y | \\lambda) = \\frac{e^{-\\lambda} \\lambda^Y}{Y!}\\)\nWe treat the observed number of patents as realizations from this distribution.\n\n\n\n# Log-likelihood function for Poisson model\npoisson_loglikelihood &lt;- function(lambda, Y) {\n  if (lambda &lt;= 0) return(-Inf)  # Poisson lambda must be positive\n  sum(dpois(Y, lambda, log = TRUE))\n}\n\n\n\n\nWe use the observed number of patents as input to our log-likelihood function.\n\nY_obs &lt;- data$patents\nlambda_vals &lt;- seq(0.1, 10, by = 0.1)\nloglik_vals &lt;- sapply(lambda_vals, function(l) poisson_loglikelihood(l, Y_obs))\n\nplot(lambda_vals, loglik_vals, type = \"l\", lwd = 2,\n     main = \"Log-Likelihood of Poisson Model\",\n     xlab = expression(lambda), ylab = \"Log-Likelihood\")\n\n\n\n\n\n\n\n\n\n\n\nWe now use optim() to find the value of lambda that maximizes the log-likelihood.\n\nmle_result &lt;- optim(par = 1, fn = function(l) -poisson_loglikelihood(l, Y_obs),\n                    method = \"Brent\", lower = 0.01, upper = 20)\n\nlambda_mle &lt;- mle_result$par\nlambda_mle\n\n[1] 3.684667\n\n\nThe MLE for \\(\\lambda\\) is the sample mean of \\(Y\\), which is consistent with theory: for Poisson-distributed data, \\(\\hat{\\lambda}_{MLE} = \\bar{Y}\\).\n\nmean(Y_obs)\n\n[1] 3.684667\n\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\n\n\npoisson_regression_loglik &lt;- function(beta, Y, X) {\n  lambda &lt;- exp(X %*% beta)\n  sum(dpois(Y, lambda, log = TRUE))\n}\n\n\n\n\n\n# Age and age squared\ndata &lt;- data %&gt;%\n  mutate(age_sq = age^2)\n\n# One-hot encode region (drop 1 category)\nregion_dummies &lt;- model.matrix(~ region, data = data)[, -1]\n\n# Final covariate matrix: intercept, age, age_sq, region dummies, customer\nX &lt;- cbind(\n  intercept = 1,\n  age = data$age,\n  age_sq = data$age_sq,\n  region_dummies,\n  iscustomer = as.numeric(data$iscustomer == \"Customer\")\n)\n\nY &lt;- data$patents\n\n\n\n\n\nloglik_wrapper &lt;- function(beta) -poisson_regression_loglik(beta, Y, X)\n\n# Initial guess\nbeta_init &lt;- rep(0, ncol(X))\n\n# Optimize\nopt_result &lt;- optim(par = beta_init, fn = loglik_wrapper, hessian = TRUE, method = \"BFGS\")\n\n# Coefficients\nbeta_hat &lt;- opt_result$par\n\n# Standard errors from Hessian\nhess_inv &lt;- solve(opt_result$hessian)\nse_hat &lt;- sqrt(diag(hess_inv))\n\n# Summary table\ncoef_table &lt;- data.frame(\n  Term = colnames(X),\n  Estimate = beta_hat,\n  StdError = se_hat\n)\n\ncoef_table\n\n             Term     Estimate     StdError\n1       intercept -0.125735914 0.1122180345\n2             age  0.115793715 0.0063574229\n3          age_sq -0.002228748 0.0000771291\n4 regionNortheast -0.024556782 0.0433762879\n5 regionNorthwest -0.034827790 0.0529311002\n6     regionSouth -0.005441860 0.0524007440\n7 regionSouthwest -0.037784109 0.0471722463\n8      iscustomer  0.060665584 0.0320588299\n\n\n\n\n\n\nglm_model &lt;- glm(patents ~ age + I(age^2) + region + iscustomer,\n                 family = poisson(link = \"log\"),\n                 data = data)\n\nsummary(glm_model)\n\n\nCall:\nglm(formula = patents ~ age + I(age^2) + region + iscustomer, \n    family = poisson(link = \"log\"), data = data)\n\nCoefficients:\n                    Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)        -0.508920   0.183179  -2.778  0.00546 ** \nage                 0.148619   0.013869  10.716  &lt; 2e-16 ***\nI(age^2)           -0.002971   0.000258 -11.513  &lt; 2e-16 ***\nregionNortheast     0.029170   0.043625   0.669  0.50372    \nregionNorthwest    -0.017574   0.053781  -0.327  0.74383    \nregionSouth         0.056561   0.052662   1.074  0.28281    \nregionSouthwest     0.050576   0.047198   1.072  0.28391    \niscustomerCustomer  0.207591   0.030895   6.719 1.83e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 2362.5  on 1499  degrees of freedom\nResidual deviance: 2143.3  on 1492  degrees of freedom\nAIC: 6532.1\n\nNumber of Fisher Scoring iterations: 5\n\n\n\n\n\nThis Poisson regression estimates the expected number of patents awarded to firms as a function of age, age squared, region, and Blueprinty software usage. Key insights include:\n\nage: The coefficient is positive and highly significant. This suggests that older firms tend to have more patents, all else equal. Specifically, a one-year increase in firm age is associated with an expected increase in patents by a factor of exp(0.1486) ≈ 1.160 (or about a 16% increase).\nI(age²): The negative and significant coefficient on age squared indicates a concave (inverted U-shaped) relationship. This means that the rate of increase in patents slows down for very old firms.\nregion: None of the regional dummy variables (Northeast, Northwest, South, Southwest) are statistically significant. This implies that — after controlling for age and Blueprinty usage — there are no strong regional differences in patent counts.\niscustomerCustomer: The coefficient is positive and highly significant (p &lt; 0.001). Using Blueprinty’s software is associated with an increase in the expected number of patents. The estimated coefficient 0.208 corresponds to a 23.1% increase in expected patent count (exp(0.208) ≈ 1.231).\n\n\n\n\n\n# Create X_0 and X_1 matrices\nX_0 &lt;- X\nX_0[, \"iscustomer\"] &lt;- 0\n\nX_1 &lt;- X\nX_1[, \"iscustomer\"] &lt;- 1\n\n# Predicted lambda for each case\nlambda_0 &lt;- exp(X_0 %*% beta_hat)\nlambda_1 &lt;- exp(X_1 %*% beta_hat)\n\n# Predicted difference\ndiff &lt;- lambda_1 - lambda_0\nmean(diff)\n\n[1] 0.2178843\n\n\nThis gives the average expected increase in the number of patents due to using Blueprinty’s software, across all firms in the dataset."
  },
  {
    "objectID": "blog/project3/hw2_questions.html#airbnb-case-study",
    "href": "blog/project3/hw2_questions.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\n\n\nExploratory Data Analysis\n\nairbnb &lt;- read_csv(\"airbnb.csv\")\n\nNew names:\nRows: 40628 Columns: 14\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(3): last_scraped, host_since, room_type dbl (10): ...1, id, days, bathrooms,\nbedrooms, price, number_of_reviews, rev... lgl (1): instant_bookable\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -&gt; `...1`\n\nglimpse(airbnb)\n\nRows: 40,628\nColumns: 14\n$ ...1                      &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 1…\n$ id                        &lt;dbl&gt; 2515, 2595, 3647, 3831, 4611, 5099, 5107, 51…\n$ days                      &lt;dbl&gt; 3130, 3127, 3050, 3038, 3012, 2981, 2981, 29…\n$ last_scraped              &lt;chr&gt; \"4/2/2017\", \"4/2/2017\", \"4/2/2017\", \"4/2/201…\n$ host_since                &lt;chr&gt; \"9/6/2008\", \"9/9/2008\", \"11/25/2008\", \"12/7/…\n$ room_type                 &lt;chr&gt; \"Private room\", \"Entire home/apt\", \"Private …\n$ bathrooms                 &lt;dbl&gt; 1, 1, 1, 1, NA, 1, 1, NA, 1, 1, 1, 1, 1, NA,…\n$ bedrooms                  &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2,…\n$ price                     &lt;dbl&gt; 59, 230, 150, 89, 39, 212, 250, 60, 129, 79,…\n$ number_of_reviews         &lt;dbl&gt; 150, 20, 0, 116, 93, 60, 60, 50, 53, 329, 11…\n$ review_scores_cleanliness &lt;dbl&gt; 9, 9, NA, 9, 9, 9, 10, 8, 9, 7, 10, 9, 9, 9,…\n$ review_scores_location    &lt;dbl&gt; 9, 10, NA, 9, 8, 9, 9, 9, 10, 10, 10, 9, 10,…\n$ review_scores_value       &lt;dbl&gt; 9, 9, NA, 9, 9, 9, 10, 9, 9, 9, 10, 9, 10, 9…\n$ instant_bookable          &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FAL…\n\nsummary(airbnb)\n\n      ...1             id                days       last_scraped      \n Min.   :    1   Min.   :    2515   Min.   :    1   Length:40628      \n 1st Qu.:10158   1st Qu.: 4889868   1st Qu.:  542   Class :character  \n Median :20314   Median : 9862878   Median :  996   Mode  :character  \n Mean   :20314   Mean   : 9698889   Mean   : 1102                     \n 3rd Qu.:30471   3rd Qu.:14667894   3rd Qu.: 1535                     \n Max.   :40628   Max.   :18009669   Max.   :42828                     \n                                                                      \n  host_since         room_type           bathrooms        bedrooms     \n Length:40628       Length:40628       Min.   :0.000   Min.   : 0.000  \n Class :character   Class :character   1st Qu.:1.000   1st Qu.: 1.000  \n Mode  :character   Mode  :character   Median :1.000   Median : 1.000  \n                                       Mean   :1.125   Mean   : 1.147  \n                                       3rd Qu.:1.000   3rd Qu.: 1.000  \n                                       Max.   :8.000   Max.   :10.000  \n                                       NA's   :160     NA's   :76      \n     price         number_of_reviews review_scores_cleanliness\n Min.   :   10.0   Min.   :  0.0     Min.   : 2.000           \n 1st Qu.:   70.0   1st Qu.:  1.0     1st Qu.: 9.000           \n Median :  100.0   Median :  4.0     Median :10.000           \n Mean   :  144.8   Mean   : 15.9     Mean   : 9.198           \n 3rd Qu.:  170.0   3rd Qu.: 17.0     3rd Qu.:10.000           \n Max.   :10000.0   Max.   :421.0     Max.   :10.000           \n                                     NA's   :10195            \n review_scores_location review_scores_value instant_bookable\n Min.   : 2.000         Min.   : 2.000      Mode :logical   \n 1st Qu.: 9.000         1st Qu.: 9.000      FALSE:32759     \n Median :10.000         Median :10.000      TRUE :7869      \n Mean   : 9.414         Mean   : 9.332                      \n 3rd Qu.:10.000         3rd Qu.:10.000                      \n Max.   :10.000         Max.   :10.000                      \n NA's   :10254          NA's   :10256                       \n\n\n\n\nData Cleaning\n\n# Drop rows with missing values in relevant columns\nairbnb_clean &lt;- airbnb %&gt;%\n  filter(\n    !is.na(number_of_reviews),\n    !is.na(review_scores_cleanliness),\n    !is.na(review_scores_location),\n    !is.na(review_scores_value),\n    !is.na(bathrooms),\n    !is.na(bedrooms),\n    !is.na(price)\n  ) %&gt;%\n  mutate(\n    instant_bookable = ifelse(instant_bookable == \"t\", 1, 0),\n    room_type = as.factor(room_type)\n  )\n\nsummary(airbnb_clean)\n\n      ...1             id                days       last_scraped      \n Min.   :    1   Min.   :    2515   Min.   :    7   Length:30160      \n 1st Qu.: 8630   1st Qu.: 4276690   1st Qu.:  584   Class :character  \n Median :18236   Median : 9149028   Median : 1041   Mode  :character  \n Mean   :18679   Mean   : 8978287   Mean   : 1140                     \n 3rd Qu.:28532   3rd Qu.:13914758   3rd Qu.: 1592                     \n Max.   :40504   Max.   :17973686   Max.   :42828                     \n  host_since                  room_type       bathrooms        bedrooms     \n Length:30160       Entire home/apt:15543   Min.   :0.000   Min.   : 0.000  \n Class :character   Private room   :13773   1st Qu.:1.000   1st Qu.: 1.000  \n Mode  :character   Shared room    :  844   Median :1.000   Median : 1.000  \n                                            Mean   :1.122   Mean   : 1.151  \n                                            3rd Qu.:1.000   3rd Qu.: 1.000  \n                                            Max.   :6.000   Max.   :10.000  \n     price         number_of_reviews review_scores_cleanliness\n Min.   :   10.0   Min.   :  1.00    Min.   : 2.000           \n 1st Qu.:   70.0   1st Qu.:  3.00    1st Qu.: 9.000           \n Median :  103.0   Median :  8.00    Median :10.000           \n Mean   :  140.2   Mean   : 21.17    Mean   : 9.202           \n 3rd Qu.:  169.0   3rd Qu.: 26.00    3rd Qu.:10.000           \n Max.   :10000.0   Max.   :421.00    Max.   :10.000           \n review_scores_location review_scores_value instant_bookable\n Min.   : 2.000         Min.   : 2.000      Min.   :0       \n 1st Qu.: 9.000         1st Qu.: 9.000      1st Qu.:0       \n Median :10.000         Median :10.000      Median :0       \n Mean   : 9.415         Mean   : 9.334      Mean   :0       \n 3rd Qu.:10.000         3rd Qu.:10.000      3rd Qu.:0       \n Max.   :10.000         Max.   :10.000      Max.   :0       \n\n\n\n\nDistribution of Reviews\n\nggplot(airbnb_clean, aes(x = number_of_reviews)) +\n  geom_histogram(bins = 50, fill = \"steelblue\", alpha = 0.7) +\n  labs(title = \"Distribution of Number of Reviews\", x = \"Number of Reviews\", y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nPoisson Regression Model\n\nmodel &lt;- glm(number_of_reviews ~ days + price + bedrooms + bathrooms +\n               review_scores_cleanliness + review_scores_location +\n               review_scores_value + instant_bookable + room_type,\n             family = poisson(link = \"log\"),\n             data = airbnb_clean)\n\nsummary(model)\n\n\nCall:\nglm(formula = number_of_reviews ~ days + price + bedrooms + bathrooms + \n    review_scores_cleanliness + review_scores_location + review_scores_value + \n    instant_bookable + room_type, family = poisson(link = \"log\"), \n    data = airbnb_clean)\n\nCoefficients: (1 not defined because of singularities)\n                            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                3.646e+00  1.595e-02 228.572  &lt; 2e-16 ***\ndays                       4.962e-05  4.029e-07 123.163  &lt; 2e-16 ***\nprice                     -3.697e-05  8.554e-06  -4.322 1.55e-05 ***\nbedrooms                   7.562e-02  2.005e-03  37.715  &lt; 2e-16 ***\nbathrooms                 -1.105e-01  3.789e-03 -29.163  &lt; 2e-16 ***\nreview_scores_cleanliness  1.138e-01  1.489e-03  76.419  &lt; 2e-16 ***\nreview_scores_location    -8.086e-02  1.600e-03 -50.527  &lt; 2e-16 ***\nreview_scores_value       -9.708e-02  1.795e-03 -54.091  &lt; 2e-16 ***\ninstant_bookable                  NA         NA      NA       NA    \nroom_typePrivate room      1.213e-02  2.735e-03   4.435 9.19e-06 ***\nroom_typeShared room      -2.172e-01  8.616e-03 -25.204  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 961626  on 30159  degrees of freedom\nResidual deviance: 940403  on 30150  degrees of freedom\nAIC: 1061889\n\nNumber of Fisher Scoring iterations: 9\n\n\n\n\nInterpretation\nThe Poisson regression model estimates how various listing characteristics influence the expected number of reviews (used as a proxy for bookings). Below are key takeaways:\n\ndays: Longer-listed properties tend to receive more reviews. Each additional day on the platform increases expected reviews by a factor of exp(4.962e-05) ≈ 1.00005.\nprice: Listings with higher nightly prices receive fewer reviews. The negative and significant coefficient suggests price sensitivity.\nbedrooms: Each additional bedroom increases expected reviews by approximately 7.8% (exp(0.0756) ≈ 1.0785).\nbathrooms: Surprisingly, more bathrooms are associated with fewer reviews, which may reflect multicollinearity or data-specific effects.\nreview_scores_cleanliness: A 1-point increase in cleanliness rating is associated with a 12% increase in expected reviews (exp(0.1138) ≈ 1.12).\nreview_scores_location and review_scores_value: These have negative coefficients, which may suggest correlation with other factors or overcontrol in the model.\nroom_type:\n\nPrivate room: Increases reviews slightly compared to entire homes (exp(0.0213) ≈ 1.0215).\nShared room: Associated with significantly fewer reviews (exp(-0.2172) ≈ 0.805).\n\ninstant_bookable: Dropped from the model due to collinearity, indicating redundancy or lack of variation.\n\n\n\nConclusion\nThe analysis shows that Airbnb listings receive more reviews (bookings) when they are: - More affordable, - Cleaner, - Have more bedrooms, - And are listed longer.\nRoom type also matters—private rooms perform slightly better than shared rooms in terms of review volume. Hosts looking to improve booking outcomes should focus on cleanliness, pricing, and overall presentation to prospective guests."
  },
  {
    "objectID": "blog/project3/blueprinty_case.html",
    "href": "blog/project3/blueprinty_case.html",
    "title": "Blueprinty Case Study",
    "section": "",
    "text": "Blueprinty is a small software firm that develops tools for creating blueprints used in patent applications. The marketing team wants to make the case that firms using Blueprinty’s product are more successful in getting patents approved.\nAlthough we don’t have before-and-after data, Blueprinty has collected cross-sectional data on 1,500 mature engineering firms, including number of patents awarded in the last 5 years, region, firm age, and whether or not the firm uses their software.\n\n\n\n\nlibrary(ggplot2)\nlibrary(readr)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\n\ndata &lt;- read_csv(\"blueprinty.csv\")\n\nRows: 1500 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): region\ndbl (3): patents, age, iscustomer\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndata &lt;- data %&gt;%\n  mutate(\n    iscustomer = factor(iscustomer, levels = c(0, 1), labels = c(\"Non-Customer\", \"Customer\"))\n  )\n\n\n\n\nggplot(data, aes(x = patents, fill = iscustomer)) +\n  geom_histogram(position = \"identity\", alpha = 0.5, bins = 30) +\n  labs(\n    title = \"Number of Patents by Customer Status\",\n    x = \"Patents (Last 5 Years)\",\n    fill = \"Customer Status\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\ndata %&gt;%\n  group_by(iscustomer) %&gt;%\n  summarise(\n    count = n(),\n    mean_patents = mean(patents),\n    sd_patents = sd(patents)\n  )\n\n# A tibble: 2 × 4\n  iscustomer   count mean_patents sd_patents\n  &lt;fct&gt;        &lt;int&gt;        &lt;dbl&gt;      &lt;dbl&gt;\n1 Non-Customer  1019         3.47       2.23\n2 Customer       481         4.13       2.55\n\n\nWe observe that Blueprinty customers, on average, have more patents over the past five years. However, this comparison does not yet account for potential confounding variables.\n\n\n\n\nggplot(data, aes(x = region, fill = iscustomer)) +\n  geom_bar(position = \"fill\") +\n  labs(\n    title = \"Regional Distribution by Customer Status\",\n    x = \"Region\",\n    y = \"Proportion of Firms\",\n    fill = \"Customer Status\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThere are noticeable regional differences in customer adoption. Some regions appear to have a higher share of Blueprinty customers.\n\n\n\n\nggplot(data, aes(x = age, fill = iscustomer)) +\n  geom_histogram(position = \"identity\", alpha = 0.5, bins = 30) +\n  labs(\n    title = \"Firm Age Distribution by Customer Status\",\n    x = \"Age (Years Since Incorporation)\",\n    fill = \"Customer Status\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\ndata %&gt;%\n  group_by(iscustomer) %&gt;%\n  summarise(\n    mean_age = mean(age),\n    sd_age = sd(age)\n  )\n\n# A tibble: 2 × 3\n  iscustomer   mean_age sd_age\n  &lt;fct&gt;           &lt;dbl&gt;  &lt;dbl&gt;\n1 Non-Customer     26.1   6.95\n2 Customer         26.9   7.81\n\n\nOn average, customers are older firms. Age may therefore be a confounding factor when evaluating patent success.\n\n\n\n\nWhile customers have more patents on average, they also differ in age and region. These structural differences suggest we should adjust for confounding variables in any attempt to infer a causal impact of Blueprinty’s software."
  },
  {
    "objectID": "blog/project3/blueprinty_case.html#blueprinty-case-study",
    "href": "blog/project3/blueprinty_case.html#blueprinty-case-study",
    "title": "Blueprinty Case Study",
    "section": "",
    "text": "Blueprinty is a small software firm that develops tools for creating blueprints used in patent applications. The marketing team wants to make the case that firms using Blueprinty’s product are more successful in getting patents approved.\nAlthough we don’t have before-and-after data, Blueprinty has collected cross-sectional data on 1,500 mature engineering firms, including number of patents awarded in the last 5 years, region, firm age, and whether or not the firm uses their software.\n\n\n\n\nlibrary(ggplot2)\nlibrary(readr)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\n\ndata &lt;- read_csv(\"blueprinty.csv\")\n\nRows: 1500 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): region\ndbl (3): patents, age, iscustomer\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndata &lt;- data %&gt;%\n  mutate(\n    iscustomer = factor(iscustomer, levels = c(0, 1), labels = c(\"Non-Customer\", \"Customer\"))\n  )\n\n\n\n\nggplot(data, aes(x = patents, fill = iscustomer)) +\n  geom_histogram(position = \"identity\", alpha = 0.5, bins = 30) +\n  labs(\n    title = \"Number of Patents by Customer Status\",\n    x = \"Patents (Last 5 Years)\",\n    fill = \"Customer Status\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\ndata %&gt;%\n  group_by(iscustomer) %&gt;%\n  summarise(\n    count = n(),\n    mean_patents = mean(patents),\n    sd_patents = sd(patents)\n  )\n\n# A tibble: 2 × 4\n  iscustomer   count mean_patents sd_patents\n  &lt;fct&gt;        &lt;int&gt;        &lt;dbl&gt;      &lt;dbl&gt;\n1 Non-Customer  1019         3.47       2.23\n2 Customer       481         4.13       2.55\n\n\nWe observe that Blueprinty customers, on average, have more patents over the past five years. However, this comparison does not yet account for potential confounding variables.\n\n\n\n\nggplot(data, aes(x = region, fill = iscustomer)) +\n  geom_bar(position = \"fill\") +\n  labs(\n    title = \"Regional Distribution by Customer Status\",\n    x = \"Region\",\n    y = \"Proportion of Firms\",\n    fill = \"Customer Status\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThere are noticeable regional differences in customer adoption. Some regions appear to have a higher share of Blueprinty customers.\n\n\n\n\nggplot(data, aes(x = age, fill = iscustomer)) +\n  geom_histogram(position = \"identity\", alpha = 0.5, bins = 30) +\n  labs(\n    title = \"Firm Age Distribution by Customer Status\",\n    x = \"Age (Years Since Incorporation)\",\n    fill = \"Customer Status\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\ndata %&gt;%\n  group_by(iscustomer) %&gt;%\n  summarise(\n    mean_age = mean(age),\n    sd_age = sd(age)\n  )\n\n# A tibble: 2 × 3\n  iscustomer   mean_age sd_age\n  &lt;fct&gt;           &lt;dbl&gt;  &lt;dbl&gt;\n1 Non-Customer     26.1   6.95\n2 Customer         26.9   7.81\n\n\nOn average, customers are older firms. Age may therefore be a confounding factor when evaluating patent success.\n\n\n\n\nWhile customers have more patents on average, they also differ in age and region. These structural differences suggest we should adjust for confounding variables in any attempt to infer a causal impact of Blueprinty’s software."
  }
]